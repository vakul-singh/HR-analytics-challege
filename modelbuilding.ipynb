{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "* I Have prepared a function which takes train data set as input.\n",
    "* Training data set is split into train and dev  set\n",
    "* Independent and Dependent variables are separated from train and  dev set\n",
    "* Used gradient booting classifier to train model with appropriate hyperparameter \n",
    "* Instead of predicting direct values of target output of dev set, probabilities are predicted\n",
    "* Threshold probabiliy is selected based on the maximum f1 score\n",
    "* Finally, all train data sets are passed through this model one by one several time\n",
    "* Some data sets performed very well those data sets wete chosen for further process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python virsion   : 3.7.1 (default, Dec 10 2018, 22:54:23) [MSC v.1915 64 bit (AMD64)]\n",
      "pandas virsion   : 0.23.4\n",
      "sklearn virsion  : 0.20.1\n",
      "numpy virsion    : 0.23.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('python virsion   :',sys.version)\n",
    "print('pandas virsion   :',pd.__version__)\n",
    "print('sklearn virsion  :',sklearn.__version__)\n",
    "print('numpy virsion    :',pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing differnt train data sets\n",
    "data= pd.read_csv('PP_train_0.csv')\n",
    "data_1= pd.read_csv('PP_train_1.csv')\n",
    "data_2= pd.read_csv('PP_train_2.csv')\n",
    "data_3= pd.read_csv('PP_train_3.csv')\n",
    "data_4= pd.read_csv('PP_train_4.csv')\n",
    "data_5= pd.read_csv('PP_train_5.csv')\n",
    "data_6= pd.read_csv('PP_train_6.csv')\n",
    "data_7= pd.read_csv('PP_train_7.csv')\n",
    "data_8= pd.read_csv('PP_train_8.csv')\n",
    "data_9= pd.read_csv('PP_train_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function\n",
    "#parameter 'd' is training data set \n",
    "def gbmodel(d):\n",
    "    #spliting train set into train and dev set, dev set is 30% of entire traning data\n",
    "    train, dev =train_test_split(d, test_size=0.3)\n",
    "    \n",
    "    #separating independent variable i.e. X and dependent variable i.e. y\n",
    "    X_train = train.drop(['is_promoted'],axis=1)\n",
    "    y_train = train['is_promoted']\n",
    "\n",
    "    X_dev = dev.drop(['is_promoted'],axis=1)\n",
    "    y_dev = dev['is_promoted']\n",
    "\n",
    "    \n",
    "    #defining the model\n",
    "    model = GradientBoostingClassifier(max_depth=10,min_samples_split=5,\n",
    "                                  min_samples_leaf=5,\n",
    "                                  min_weight_fraction_leaf=0,n_estimators=1000)\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    #predicting probabiltiy of target variable of dev set\n",
    "    y_prob_dev = model.predict_proba(X_dev)\n",
    "    \n",
    "    #applying 'for loop' for getting max f1 score and respective threshold \n",
    "    f1score = []\n",
    "    max_f1 =0\n",
    "    x =[]\n",
    "    for i in range(100):\n",
    "        y_hat_prob_dev = y_prob_dev[:,1]> i/100\n",
    "        f1 = f1_score(y_dev, y_hat_prob_dev)\n",
    "        f1score.append(f1)\n",
    "        x.append(i)\n",
    "        if f1 > max_f1:\n",
    "            max_f1 = f1\n",
    "            threshold= i/100\n",
    "    print('maximum f1 score :',max_f1)\n",
    "    print('thresold         :',threshold)\n",
    "    \n",
    "#this function print max f1 score and respective threshold     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying function on differend data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data 0:')\n",
    "gbmodel(data)\n",
    "print('          ')\n",
    "print('data 1:')\n",
    "gbmodel(data_1)\n",
    "print('          ')\n",
    "print('data 2:')\n",
    "gbmodel(data_2)\n",
    "print('          ')\n",
    "print('data 3:')\n",
    "gbmodel(data_3)\n",
    "print('          ')\n",
    "print('data 4:')\n",
    "gbmodel(data_4)\n",
    "print('          ')\n",
    "print('data 5:')\n",
    "gbmodel(data_5)\n",
    "print('          ')\n",
    "print('data 6:')\n",
    "gbmodel(data_6)\n",
    "print('          ')\n",
    "print('data 7:')\n",
    "gbmodel(data_7)\n",
    "print('          ')\n",
    "print('data 8:')\n",
    "gbmodel(data_8)\n",
    "print('          ')\n",
    "print('data 9:')\n",
    "gbmodel(data_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
